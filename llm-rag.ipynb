{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_community.llms import Ollama # old\n",
    "from langchain_ollama import ChatOllama # new\n",
    "from langchain_ollama import OllamaLLM\n",
    "#from langchain_community.vectorstores import Chroma # old\n",
    "from langchain_chroma import Chroma\n",
    "#from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93018cd",
   "metadata": {},
   "source": [
    "- Initiate VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40740200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding\n",
    "# oembed = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"nomic-embed-text\")\n",
    "oembed = OllamaEmbeddings(model=\"llama3.2:1b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5aa865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to existing vectorstore\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"address_metadata\",\n",
    "    embedding_function=oembed,\n",
    "    persist_directory=\"./vectorstore\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8753ad54",
   "metadata": {},
   "source": [
    "- Initiate LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c7bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "#llm = Ollama(model=\"deepseek-r1:14b\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = OllamaLLM(model=\"deepseek-r1:14b\", base_url=\"http://localhost:11434\")\n",
    "# llm = ChatOllama(model=\"deepseek-r1:14b\", base_url=\"http://localhost:11434\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"Hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c301273",
   "metadata": {},
   "source": [
    "- RAG retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# Initialize the persistent ChromaDB client\n",
    "# chroma_client = chromadb.PersistentClient(path=\"./vectorstore\")\n",
    "chroma_client = chromadb.PersistentClient(path=\"https://drive.google.com/drive/folders/1tl1V-lsDYSt5GFILaKowd0pDM00Z5DX7\")\n",
    "\n",
    "# List all collections in the database\n",
    "collections = chroma_client.list_collections()\n",
    "print(\"Collections in the database:\")\n",
    "for collection in collections:\n",
    "    # Print the collection name directly since collection is now a string\n",
    "    print(collection)\n",
    "\n",
    "# If you need to work with a specific collection, use get_collection():\n",
    "# Example:\n",
    "# collection = chroma_client.get_collection(name=\"your_collection_name\")\n",
    "\n",
    "address = chroma_client.get_collection(name=\"address_metadata\")\n",
    "\n",
    "# show the number of documents in the collection\n",
    "print(address.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db833d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "state = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"state\"]].drop_duplicates()['state'].str.lower().tolist()\n",
    "district = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"district\"]].drop_duplicates()['district'].str.lower().tolist()\n",
    "mukim = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"mukim\"]].dropna().drop_duplicates()['mukim'].str.lower().tolist()\n",
    "location = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "\n",
    "postcode = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\",dtype='str')[[\"postcode\"]].dropna().drop_duplicates()['postcode'].str.lower().tolist()\n",
    "postcode = [x.strip() for x in list(set(postcode)) for x in x.split(\",\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501659f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"235, pintasan mayang 1, persiaran mayang pasir, 11900, mukim 12, pulau pinang\"\n",
    "\n",
    "# find the state, district, mukim and location in the string\n",
    "state_found = [s for s in state if s in input_str.lower()] # case len = 1 , case len = 0 , case len > 1\n",
    "district_found = [d for d in district if d in input_str.lower()]\n",
    "mukim_found = [m for m in mukim if m in input_str.lower()]\n",
    "location_found = [l for l in location if l in input_str.lower()]  # Convert float to string\n",
    "\n",
    "postcode_found = [p for p in postcode if p in input_str.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_found)\n",
    "print(district_found)  \n",
    "print(mukim_found)\n",
    "print(location_found)\n",
    "\n",
    "print(postcode_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1)state_found --|-->--- 2)district_found --|-->---- 4)mukim_found --|--->--- 8)location_found\n",
    "                |                          |                        |--->--- 9)not location_found\n",
    "                |                          |    \n",
    "                |                          |--> 5)not mukim_found --|--->--- 10)location_found\n",
    "                |                                                   |--->--- 11)not location_found\n",
    "                |\n",
    "                |\n",
    "                |--> 3)no district_found --|-->---- 6)mukim_found --|--->--- 12)location_found\n",
    "                                           |                        |--->--- 13)not location_found\n",
    "                                           |                      \n",
    "                                           |--> 7)not mukim_found --|--->--- 14)location_found   \n",
    "                                                                    |--->--- 15)not location_found\n",
    "'''\n",
    "'''             |                          |                        |\n",
    "    Level 1     |               Level 2    |             Level 3    |             Level 4   \n",
    "                |                          |                        |              \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_update = []\n",
    "district_update = []\n",
    "mukim_update = []\n",
    "location_update = []\n",
    "\n",
    "\n",
    "str = \"235, pintasan mayang 1, persiaran mayang pasir, 11900, bayan lepas, pulau pinang\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bffe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 1,2,3,4\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=pd.errors.DtypeWarning)\n",
    "\n",
    "state = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"state\"]].drop_duplicates()['state'].str.lower().tolist()\n",
    "district = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"district\"]].drop_duplicates()['district'].str.lower().tolist()\n",
    "mukim = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"mukim\"]].dropna().drop_duplicates()['mukim'].str.lower().tolist()\n",
    "location = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "\n",
    "# find the state, district, mukim and location in the string\n",
    "state_found = [s for s in state if s in str.lower()] # case len = 1 , case len = 0 , case len > 1\n",
    "district_found = [d for d in district if d in str.lower()]\n",
    "mukim_found = [m for m in mukim if m in str.lower()]\n",
    "location_found = [l for l in location if l in str.lower()]  # Convert float to string\n",
    "\n",
    "# 1)\n",
    "if len(state_found) == 1:                                                                                                                 \n",
    "    print(\"State found:\", state_found[0])\n",
    "\n",
    "    state_update=state_update+(state_found)\n",
    "\n",
    "    state = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")\n",
    "    \n",
    "    #filter state_found\n",
    "    state = state[state['state'].str.lower() == state_found[0]]\n",
    "\n",
    "    #update district_found\n",
    "    district = state[[\"district\"]].drop_duplicates()['district'].str.lower().tolist()\n",
    "    district_found = [d for d in district if d in str.lower()]\n",
    "\n",
    "    ####################################################################################################################\n",
    "\n",
    "    # 2)\n",
    "    if district_found:\n",
    "                                                                                                                                                                                             \n",
    "        for district in district_found:\n",
    "\n",
    "            # district name is not the same as state name\n",
    "            # 2a)\n",
    "            if district != state_found[0]:                                                                                                   \n",
    "                print(f\"District found for the state {state_found[0]}:\", district)\n",
    "                district_update=district_update+([district])\n",
    "                # filter the district\n",
    "                district_case1 = state[state['district'].str.lower() == district]\n",
    "                # update mukim_found\n",
    "                mukim = district_case1[[\"mukim\"]].dropna().drop_duplicates()['mukim'].str.lower().tolist()\n",
    "                mukim_found = [m for m in mukim if m in str.lower()]\n",
    "\n",
    "            ##########################################################################################################\n",
    "\n",
    "                # 4)\n",
    "                if mukim_found:\n",
    "                    for mukim in mukim_found:\n",
    "                        # mukim name is not the same as district name\n",
    "                        if mukim != district:\n",
    "                            print(\"Mukim name found not same as district name:\", mukim)\n",
    "                            mukim_update=mukim_update+([mukim])\n",
    "                            # filter the mukim\n",
    "                            mukim_case1 = district_case1[district_case1['mukim'].str.lower() == mukim]\n",
    "                            # update location_found\n",
    "                            location = mukim_case1[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "                            #location_found = [l for l in location if l in str.lower()]\n",
    "                            location_found = [x for x in [l for l in location if l.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "                            # 8) [1248]\n",
    "                            if location_found:\n",
    "                                for location in location_found:\n",
    "                                    if location != mukim_found[0]:\n",
    "                                        print(f\"Location found for the mukim {mukim}:\", location)\n",
    "                                        location_update=location_update+([location])\n",
    "                        # mukim name is the same as district name\n",
    "                        elif mukim == district:\n",
    "                            print(\"Mukim name found same as district name\")\n",
    "                            mukim_update=mukim_update+([mukim])\n",
    "                            # filter the mukim\n",
    "                            mukim_case2 = district_case1[district_case1['mukim'].str.lower() == mukim]\n",
    "                            # update location_found\n",
    "                            # 8) [1248]\n",
    "                            location = mukim_case2[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "                            #location_found = [l for l in location if l in str.lower()]\n",
    "                            location_found = [x for x in [l for l in location if l.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "                            print(f\"Location found for the mukim {mukim}:\", location)\n",
    "                            location_update=location_update+([location])\n",
    "\n",
    "            ##########################################################################################################\n",
    "\n",
    "                # 5)    \n",
    "                elif not mukim_found:\n",
    "                    print(\"No Mukim found for the district:\", district)                    \n",
    "                    # update location_found\n",
    "                    location = district_case1[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "                    #location_found = [l for l in location if l in str.lower()]\n",
    "                    location_found = [x for x in [l for l in location if l.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "                    # 10) [12510]\n",
    "                    if location_found:\n",
    "                        for location in location_found:\n",
    "                            if location != district:\n",
    "                                print(f\"Location found for the district {district}:\", location)\n",
    "                                location_update=location_update+([location])\n",
    "            \n",
    "            ##########################################################################################################\n",
    "            \n",
    "            # district name is the same as state name\n",
    "            # 2b)\n",
    "            elif district == state_found[0]:\n",
    "\n",
    "                print(f\"District found for the state {state_found[0]}:\", district)\n",
    "                district_update=district_update+([district])\n",
    "\n",
    "                # filter the district\n",
    "                district_case2 = state[state['district'].str.lower() == district]\n",
    "                \n",
    "                # update mukim_found\n",
    "                mukim = district_case2[[\"mukim\"]].dropna().drop_duplicates()['mukim'].str.lower().tolist()\n",
    "                mukim_found = [l for l in mukim if l in str.lower()]\n",
    "\n",
    "            ##########################################################################################################\n",
    "            \n",
    "                # 4)\n",
    "                if mukim_found:\n",
    "                    for mukim in mukim_found:\n",
    "                        # mukim name is not the same as district name\n",
    "                        if mukim != district:\n",
    "                            print(\"Mukim name found not same as district name:\", mukim)\n",
    "                            mukim_update=mukim_update+([mukim])\n",
    "                            # filter the mukim\n",
    "                            mukim_case1 = district_case2[district_case2['mukim'].str.lower() == mukim]\n",
    "                            # update location_found\n",
    "                            location = mukim_case1[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "                            #location_found = [l for l in location if l in str.lower()]\n",
    "                            location_found = [x for x in [l for l in location if l.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "                            # 8) [1248]\n",
    "                            if location_found:\n",
    "                                for location in location_found:\n",
    "                                    if location != mukim_found[0]:\n",
    "                                        print(f\"Location found for the mukim {mukim}:\", location)\n",
    "                                        location_update=location_update+([location])\n",
    "                        # mukim name is the same as district name\n",
    "                        elif mukim == district:\n",
    "                            print(\"Mukim name found same as district name\")\n",
    "                            mukim_update=mukim_update+([mukim])\n",
    "                            # filter the mukim\n",
    "                            mukim_case2 = district_case2[district_case2['mukim'].str.lower() == mukim]\n",
    "                            # update location_found\n",
    "                            # 8) [1248]\n",
    "                            location = mukim_case2[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "                            #location_found = [l for l in location if l in str.lower()]\n",
    "                            location_found = [x for x in [l for l in location if l.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "                            print(f\"Location found for the mukim {mukim}:\", location)\n",
    "                            location_update=location_update+([location])\n",
    "\n",
    "\n",
    "            ##########################################################################################################\n",
    "\n",
    "                # 5)    \n",
    "                elif not mukim_found:\n",
    "                    print(\"No Mukim found for the district:\", district)                    \n",
    "                    # update location_found\n",
    "                    location = district_case2[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "                    #location_found = [l for l in location if l in str.lower()]\n",
    "                    location_found = [x for x in [l for l in location if l.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "                    # 10) [12510]\n",
    "                    if location_found:\n",
    "                        for location in location_found:\n",
    "                            if location != district:\n",
    "                                print(f\"Location found for the district {district}:\", location)\n",
    "                                location_update=location_update+([location])\n",
    "print()\n",
    "print(\"state_update:\", state_update)\n",
    "print(\"district_update:\", district_update)\n",
    "print(\"mukim_update:\", mukim_update)\n",
    "print(\"location_update:\", location_update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74fdaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 1,3,4\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=pd.errors.DtypeWarning)\n",
    "\n",
    "state = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"state\"]].drop_duplicates()['state'].str.lower().tolist()\n",
    "district = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"district\"]].drop_duplicates()['district'].str.lower().tolist()\n",
    "mukim = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"mukim\"]].dropna().drop_duplicates()['mukim'].str.lower().tolist()\n",
    "location = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "\n",
    "# find the state, district, mukim and location in the string\n",
    "state_found = [s for s in state if s in str.lower()] # case len = 1 , case len = 0 , case len > 1\n",
    "district_found = [d for d in district if d in str.lower()]\n",
    "mukim_found = [m for m in mukim if m.lower() in str.lower()]\n",
    "location_found = [l for l in location if l in str.lower()]  # Convert float to string\n",
    "\n",
    "# 1)\n",
    "if len(state_found) == 1:                                                                                                                 \n",
    "    print(\"State found:\", state_found[0])\n",
    "\n",
    "    state_update=state_update+(state_found)\n",
    "\n",
    "    state = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")\n",
    "    \n",
    "    #filter state_found\n",
    "    state = state[state['state'].str.lower() == state_found[0]]\n",
    "\n",
    "    #update mukim_found\n",
    "    mukim = state[[\"mukim\"]].dropna().drop_duplicates()['mukim'].str.lower().tolist()\n",
    "    mukim_found = [x for x in [m for m in mukim if m.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "\n",
    "    ####################################################################################################################\n",
    "\n",
    "\n",
    "    # 4)\n",
    "    if mukim_found:\n",
    "        for mukim in mukim_found:\n",
    "            # mukim name is not the same as district name\n",
    "            if mukim != state_found[0]:\n",
    "                print(\"Mukim name found not same as state name:\", mukim)\n",
    "                mukim_update=mukim_update+([mukim])\n",
    "                # filter the mukim\n",
    "                mukim_case1 = state[state['mukim'].str.lower() == mukim]\n",
    "                # update location_found\n",
    "                location = mukim_case1[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "                #location_found = [l for l in location if l in str.lower()]\n",
    "                location_found = [x for x in [l for l in location if l.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "                # 8) [148]\n",
    "                if location_found:\n",
    "                    for location in location_found:\n",
    "                        if location != mukim_found[0]:\n",
    "                            print(f\"Location found for the mukim {mukim}:\", location)\n",
    "                            location_update=location_update+([location])\n",
    "            # mukim name is the same as district name\n",
    "            elif mukim == state_found[0]:\n",
    "                print(\"Mukim name found same as state name\")\n",
    "                mukim_update=mukim_update+([mukim])\n",
    "                # filter the mukim\n",
    "                mukim_case2 = state[state['mukim'].str.lower() == mukim]\n",
    "                # update location_found\n",
    "                # 8) [148]\n",
    "                location = mukim_case2[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "                #location_found = [l for l in location if l in str.lower()]\n",
    "\n",
    "                location_found = [x for x in [l for l in location if l.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "\n",
    "                print(f\"Location found for the mukim {mukim}:\", location)\n",
    "                location_update=location_update+([location])\n",
    "\n",
    "##########################################################################################################\n",
    "\n",
    "    # 5)    \n",
    "    elif not mukim_found:\n",
    "        print(\"No Mukim found for the state:\", state_found[0])                    \n",
    "        # update location_found\n",
    "        location = state[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "        #location_found = [l for l in location if l in str.lower()]\n",
    "        location_found = [x for x in [l for l in location if l.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "        # 10) [12510]\n",
    "        if location_found:\n",
    "            for location in location_found:\n",
    "                if location != state_found[0]:\n",
    "                    print(f\"Location found for the state {state_found[0]}:\", location)\n",
    "                    location_update=location_update+([location])\n",
    "\n",
    "##########################################################################################################\n",
    "            \n",
    "print()\n",
    "print(\"state_update:\", state_update)\n",
    "print(\"district_update:\", district_update)\n",
    "print(\"mukim_update:\", mukim_update)\n",
    "print(\"location_update:\", location_update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27552bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 1,4\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=pd.errors.DtypeWarning)\n",
    "\n",
    "state = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"state\"]].drop_duplicates()['state'].str.lower().tolist()\n",
    "district = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"district\"]].drop_duplicates()['district'].str.lower().tolist()\n",
    "mukim = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"mukim\"]].dropna().drop_duplicates()['mukim'].str.lower().tolist()\n",
    "location = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")[[\"location\"]].dropna().drop_duplicates()['location'].str.lower().tolist()\n",
    "\n",
    "# find the state, district, mukim and location in the string\n",
    "state_found = [s for s in state if s in str.lower()] # case len = 1 , case len = 0 , case len > 1\n",
    "district_found = [d for d in district if d in str.lower()]\n",
    "mukim_found = [m for m in mukim if m.lower() in str.lower()]\n",
    "location_found = [l for l in location if l in str.lower()]  # Convert float to string\n",
    "\n",
    "# 1)\n",
    "if len(state_found) == 1:                                                                                                                 \n",
    "    print(\"State found:\", state_found[0])\n",
    "\n",
    "    state_update=state_update+(state_found)\n",
    "\n",
    "    state = pd.read_csv(\"malaysia-postcodes-location-mukim-district-state.csv\")\n",
    "    \n",
    "    #filter state_found\n",
    "    state = state[state['state'].str.lower() == state_found[0]]\n",
    "\n",
    "    ####################################################################################################################\n",
    "\n",
    "    #location_found = [l for l in location if l in str.lower()]\n",
    "    location_found = [x for x in [l for l in location if l.lower() in str.lower()] if x in [x.strip() for x in str.lower().strip().split(',')]]\n",
    "    # 8) [18]\n",
    "    if location_found:\n",
    "        for location in location_found:\n",
    "            if location != state_found[0]:\n",
    "                print(f\"Location found for the state {state_found[0]}:\", location)\n",
    "                location_update=location_update+([location])\n",
    "\n",
    "    ##########################################################################################################\n",
    "            \n",
    "print()\n",
    "print(\"state_update:\", state_update)\n",
    "print(\"district_update:\", district_update)\n",
    "print(\"mukim_update:\", mukim_update)\n",
    "print(\"location_update:\", location_update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad03f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_update = list(set(state_update))\n",
    "district_update = list(set(district_update))\n",
    "mukim_update = list(set(mukim_update))\n",
    "location_update = list(set(location_update))\n",
    "print()\n",
    "print(\"state_update:\", state_update)\n",
    "print(\"district_update:\", district_update)\n",
    "print(\"mukim_update:\", mukim_update)\n",
    "print(\"location_update:\", location_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7417bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from address_parser import extract_address_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a066cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"No. 4, Gerai Penjaja, Lorong Belakang 43300 Majlis Perbandaran Kajang Selangor\"\n",
    "extract_address_metadata(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e34cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.strip() for x in str.lower().strip().split(',')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61148d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b251676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be0a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b7324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874473fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e16000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retrievers\n",
    "similarity_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3, \"filter\": {\"$contains\":\"pulau pinang\"}}) # 1)\n",
    "similarity_score_threshold_retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.8}) # 2)\n",
    "mmr_retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3 , 'lambda_mult': 0.9}) # 3)\n",
    "#euclidean_retriever = vectorstore.as_retriever(search_type=\"euclidean\", search_kwargs={\"k\": 5}) # 4)\n",
    "\n",
    "# Establish EnsembleRetriever approach (combination of multiple retrievers)\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[similarity_retriever,mmr_retriever],\n",
    "    weights=[0.95,0.05],\n",
    "    # retrieval_strategy=\"max\",\n",
    "    top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc44af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RetrievalQA chain\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=similarity_retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.search(\"persiaran mayang pasir\",k=3,search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44422b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the chain with a sample query\n",
    "query = \"persiaran mayang pasir, bayan lepas\"\n",
    "query = query.lower()\n",
    "results = similarity_retriever.invoke(query)\n",
    "\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search_with_score(\n",
    "    \"taman teratai\",\n",
    "    k=3,\n",
    "    #filter={\"$contains\":\"kedah\"},\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f17332",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectorstore.similarity_search_by_vector(\n",
    "    embedding=oembed.embed_query(\"kedah\"), k=3\n",
    ")\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
